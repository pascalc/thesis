\subsection{How are these texts evaluated?}

Criticising fictional texts is hard, we can see that much from the
disagreement that often surrounds literary criticism. One person's
favourite character might be the least favourite of another, and so on.
This makes it difficult for a single teacher, or any single
grade-setter, to pass judgement on a work of fiction.

In \emph{Narrative Roulette}, the entire readership of a work passes
judgement on a work. Currently, they do this by reading each other's
work in groups, and discussing them. The software can track how many
times a work has been read. In the future, the software will allow
readers to signal that they like a work, and to share it.

This allows for many dimensions in which works can be evaluated. A work of
fiction that no-one reads is a failure on a functional level - texts
exist to be read, so if no-one reads a text, it failed at what it was
meant to do. We could call texts that no-one reads \emph{valueless}.

Some texts will cause controversy. This means that the texts are read
and then fiercely debated. Sometimes, debaters will not approve of the
text. But the fact that the debaters read it, and then found things in
the text worthy of discussion, means that the text has some value.

Other texts will be liked by the majority of readers. This does not
necessarily make them \emph{better} than the more controversial works.
But near universal reader approval is still a form of success, as it means
that many people read the work. As with the controversial texts, the fact
that people read the work, and found things in the text worthy of
liking, means the text has value.

In this way, texts are primarily evaluated on their \emph{readability},
by the reading behaviour of other students - the writer's peers. This
can be called a \emph{structural} evaluation of a student's writing: how
good they are at communicating their ideas to their peers through the medium of
natural language.

The \emph{content} of a student's writing is evaluated by how much
discussion it generates, and how many people are willing to share it and like it.
Review-style comments (``I liked this part, but not this part'') count
as discussion.

This means that the traditional way of evaluating student's texts, where a
teacher writes a review (with an accompanying
grade), is just one component of a work's overall evaluation in the 
\emph{Narrative Roulette} microworld, instead of being the single authoritative evaluation as before. This makes a teacher's (or grade-setter's)
opinion less important. If a teacher considers a work of low value, but
the writer's peers all read, share and discuss it, the work will have high value
\emph{despite what the teacher thinks}.

This makes evaluation more democratic, and more like real-life. At school, a teacher or other authority's opinion of work has the power to
negatively affect a student's future: ``If you don't write your essay
using this exact structure, you'll get a bad grade, and not be able to
go to the university you want to.'' But after leaving school, the \emph{functional value} of work becomes all-important: ``If people don't read
your articles, we won't make money from ads on them, so you won't have a job at this company.'' Which
means that \emph{Narrative Roulette}'s form of evaluation is better
preparation for real-life than the evaluation methods of traditional school.

----------------------- From 9.tex

So is there any \textbf{evidence} that iterating the loop led to learning for the students taking part? 

Let's try and evaluate \emph{Narrative Roulette} submissions according to the framework set out in the previous chapter. 

The first question is: were texts read by students - did the texts fulfil their purpose? According to the behaviour tracking software I had on the site, \href{http://mixpanel.com}{Mixpanel}, the following submissions had significant reading activity:

\begin{center}
  \begin{tabular}{ | l | r | }
    \hline
    \textbf{Submission} & \textbf{Number of pageviews}\\ \hline
    \href{http://kg.narrativeroulette.com/submission/156}{156} & 229 \\
    \href{http://kg.narrativeroulette.com/submission/15}{15} & 114 \\
    \href{http://kg.narrativeroulette.com/submission/16}{16} & 105 \\
    \href{http://kg.narrativeroulette.com/submission/25}{25} & 52 \\
    \href{http://kg.narrativeroulette.com/submission/26}{26} & 45 \\
    \href{http://kg.narrativeroulette.com/submission/27}{27}  & 42 \\
    \hline
  \end{tabular}
\end{center}

This proves that students read each others' work, even though they didn't have to. They knew they weren't being graded for this exercise, and as I and the class teacher were the only adults in a room with 30 students, we couldn't keep an eye on all of them at the same time. They could have been doing other things on their laptops when we weren't looking at their screens.

But they didn't. The data corroborates what I saw - students were engaged in both reading and writing their texts. According to the framework set out in the previous section, this means that the texts fulfilled their purpose - they were read by others. 

